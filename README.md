# CS6140_Final

Abstract: **This project focuses on the Stanford Dogs Dataset. A convolutional neural network and a fully connected network were created to correcftly classify dog breeds based off of RGB  images. The results between each neural network were compared and it was determined that the convolutional neural network outperforms the fully connected network, but is still very prone to overfitting of the dataset.**

**Overview**:
  The main problem being solved in this project is image classification. There is a set of images containing 120 dog breeds, and the problem is that there is no neural network to classify them into groups. The motivation behind this problem is that if a neural network is created that can accurately classify dog breeds, then it could likely be easily generalized to classify other things as well. Possible expansions would be to classify multiple different subspecies of animals including dogs. This is an interesting problem because the machine learning task of image classification is a very common problem in industry today. Very large and robust models are being created to be able to classify a large range of items. One major task that these models are undertaking is their usage in self-driving car systems. These classification models can be used to classify objects detected in front of cars, determining what actions need to be taken.
  Using a neural network to solve this problem was a clear approach. Neural networks are very useful for processing images and making predictions. In addition to this, convolutinoal neural networks are even better for image classification, making for an initial hypothesis that the CNN will outperform any fully connected network. This problem of image classification is a very common one, especially with the stanford dogs datasets. It appears that almost all approaches use some kind of neural network for classifying the dog breeds. The key components of this approach is the neural network architecture. The different layering of dense and convolutional layers was very important in creating a usable model. The key result is the training and test accuracy on the dataset. With a properly performing model, the training and test accurcy should be fairly high, and the neural network should be able to classify images that it has never seen before. One major limitation found during the project was computation time. Google Colab was utilized for GPU acceleration, however even with this acceleration the training time for the models was still rather high. The cause of this limitation was likely due to the very large dataset being used, where the train/test datasplit was around 700 MB and 100 MB respectively. 

**Experiment Setup**
